{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11816223,"sourceType":"datasetVersion","datasetId":7421761}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%bash\ngit clone https://github.com/sunnytqin/no-distillation.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T01:43:11.400890Z","iopub.execute_input":"2025-05-16T01:43:11.401469Z","iopub.status.idle":"2025-05-16T01:43:11.425331Z","shell.execute_reply.started":"2025-05-16T01:43:11.401445Z","shell.execute_reply":"2025-05-16T01:43:11.424353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\nmkdir -p /kaggle/working/expert_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T01:59:42.024552Z","iopub.execute_input":"2025-05-16T01:59:42.024957Z","iopub.status.idle":"2025-05-16T01:59:42.034882Z","shell.execute_reply.started":"2025-05-16T01:59:42.024934Z","shell.execute_reply":"2025-05-16T01:59:42.034179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\nmkdir -p /kaggle/working/data/tiny-imagenet-200\n\nSRC=tiny-imagenet-200\n\ncp -r /kaggle/input/tiny-imagenet-200/$SRC/* /kaggle/working/data/tiny-imagenet-200/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T02:03:24.496551Z","iopub.execute_input":"2025-05-16T02:03:24.496820Z","iopub.status.idle":"2025-05-16T02:18:25.800175Z","shell.execute_reply.started":"2025-05-16T02:03:24.496803Z","shell.execute_reply":"2025-05-16T02:18:25.799398Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\ncd /kaggle/working/data/tiny-imagenet-200/val\n\nawk '{print $1, $2}' val_annotations.txt | \\\nwhile read IMG CLS; do\n  mkdir -p images/$CLS\n  mv images/$IMG images/$CLS/\ndone","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T02:18:25.801294Z","iopub.execute_input":"2025-05-16T02:18:25.801612Z","iopub.status.idle":"2025-05-16T02:18:57.375710Z","shell.execute_reply.started":"2025-05-16T02:18:25.801595Z","shell.execute_reply":"2025-05-16T02:18:57.375161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import defaultdict\nimport os, torch\nfrom torch import nn\n\nimport numpy as np\n\nimport os\nimport sys\nfrom tqdm import tqdm\nfrom datetime import datetime\n\nimport sys, os\n\nrepo_root = \"/kaggle/working/no-distillation\"\n\nif repo_root not in sys.path:\n    sys.path.insert(0, repo_root)\n\ntrain_exp = os.path.join(repo_root, \"train_expert\")\nif train_exp not in sys.path:\n    sys.path.insert(0, train_exp)\n\nsoftlabel_dir = os.path.join(repo_root, \"softlabel\")\nif softlabel_dir not in sys.path:\n    sys.path.insert(0, softlabel_dir)\n\n# now your imports will resolve correctly:\nfrom softlabel.utils import (\n    get_dataset,\n    get_network,\n    get_daparam,\n    TensorDataset,\n    ParamDiffAug,\n    DiffAugment,\n    augment\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T02:31:29.510331Z","iopub.execute_input":"2025-05-16T02:31:29.510820Z","iopub.status.idle":"2025-05-16T02:31:29.516166Z","shell.execute_reply.started":"2025-05-16T02:31:29.510796Z","shell.execute_reply":"2025-05-16T02:31:29.515510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ConvNet(nn.Module):\n    def __init__(self, channel, num_classes, net_width, net_depth, im_size):\n        super(ConvNet, self).__init__()\n\n        self.net_depth = net_depth\n        self.net_width = net_width\n        self.channel = channel\n        self.im_size = im_size\n        self.shape_feat = [self.net_width, self.im_size[0] // (2 ** self.net_depth), self.im_size[1] // (2 ** self.net_depth)]\n\n        self.convs = nn.ModuleList([\n            nn.Conv2d(self.channel if i == 0 else self.net_width, self.net_width, kernel_size=3, padding=1)\n            for i in range(self.net_depth)\n        ])\n\n        self.norms = nn.ModuleList([\n            nn.GroupNorm(self.net_width, self.net_width)\n            for _ in range(self.net_depth)\n        ])\n        \n        self.activation = nn.ReLU(inplace=True)\n\n        self.pooling = nn.AvgPool2d(kernel_size=2, stride=2)\n\n        num_feat = self.shape_feat[0] * self.shape_feat[1] * self.shape_feat[2]\n        self.classifier = nn.Linear(num_feat, num_classes)\n\n    def forward(self, x):\n\n        out = x\n        for d in range(self.net_depth):\n            out = self.convs[d](out)\n            out = self.norms[d](out)\n            out = self.activation(out)\n            out = self.pooling(out)\n            self.shape_feat[1] //= 2\n            self.shape_feat[2] //= 2\n        \n        out = out.view(out.size(0), -1)\n        out = self.classifier(out)\n        return out","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T01:56:53.758234Z","iopub.execute_input":"2025-05-16T01:56:53.759119Z","iopub.status.idle":"2025-05-16T01:56:53.766438Z","shell.execute_reply.started":"2025-05-16T01:56:53.759093Z","shell.execute_reply":"2025-05-16T01:56:53.765559Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Expert","metadata":{}},{"cell_type":"code","source":"def epoch(mode, dataloader, net, optimizer, criterion, args, aug):\n    loss_avg, acc_avg, num_exp = 0, 0, 0\n    net = net.to(args.device)\n\n    if mode == 'train':\n        net.train()\n    else:\n        net.eval()\n\n    for i_batch, datum in enumerate(dataloader):\n        img =  datum[0].float().to(args.device)\n        lab = datum[1].to(args.device)\n\n        if aug:\n            if args.dsa:\n                img = DiffAugment(img, args.dsa_strategy, param=args.dsa_param)\n            else:\n                img = augment(img, args.dc_aug_param, device=args.device)\n\n        n_b = lab.shape[0]\n\n        output = net(img)\n        loss = criterion(output, lab)\n\n        if (mode == 'train' and args.teacher_label) or (mode == 'train' and len(datum[1].shape)> 1) :\n            acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), np.argmax(datum[1].cpu().data.numpy(), axis=-1)))\n        else:\n            acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), lab.cpu().data.numpy()))\n            if args.selection_strategy in ['data_efficient_treat_label','data_efficient_treat_image', 'data_efficient_control']:\n                # only examine treatment subject\n                subject_idx = torch.where(lab == args.treat_subject)[0].cpu().data.numpy()\n                n_b = len(subject_idx)\n                acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1)[subject_idx], lab.cpu().data.numpy()[subject_idx]))\n               \n        loss_avg += loss.item()*n_b\n        acc_avg += acc\n        num_exp += n_b\n\n        if mode == 'train':\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n    loss_avg /= num_exp\n    acc_avg /= num_exp\n\n    return loss_avg, acc_avg, net\n\n\ndef expert_train(train_epochs):\n    dataset            = \"Tiny\"\n    subset             = \"imagenette\"\n    model_name         = \"ConvNetD4\"\n    num_experts        = 1\n    lr_teacher         = 0.01\n    batch_train        = 256\n    batch_real         = 256\n    dsa                = True\n    dsa_strategy       = \"color_crop_cutout_flip_scale_rotate\"\n    train_epochs       = train_epochs # trains up to these amount of epochs, noting params for each epoch\n    momentum           = 0.0\n    weight_decay       = 0.0\n    save_interval      = 1\n    data_path          = \"/kaggle/working/data/tiny-imagenet-200\"\n    buffer_path        = \"/kaggle/working/no-distillation/results_100_S/\"\n\n    device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    dsa_param = ParamDiffAug()\n\n    class A: pass\n    args = A()\n    args.dataset  = dataset\n    args.data_path= data_path\n    args.batch_real = batch_real\n    args.dsa      = dsa\n    args.dsa_strategy = dsa_strategy\n    args.dsa_param    = dsa_param\n    args.zca = False\n    args.device = device\n    args.teacher_label = False\n    args.selection_strategy = \"random\"\n\n    channel, im_size, num_classes, _, _, _, \\\n    dst_train, dst_test, testloader, *_ = get_dataset(\n        dataset, data_path, batch_real, args=args\n    )\n\n    save_dir = os.path.join(buffer_path, dataset, subset, model_name)\n    os.makedirs(save_dir, exist_ok=True)\n\n    images, labels = [], []\n    for img, lbl in tqdm(dst_train, desc=\"Loading real data\"):\n        images.append(img.unsqueeze(0))\n        labels.append(lbl)\n    images = torch.cat(images, 0).cpu()\n    labels = torch.tensor(labels, dtype=torch.long)\n\n    tensor_train = TensorDataset(images, labels)\n    trainloader  = torch.utils.data.DataLoader(\n        tensor_train, batch_size=batch_train, shuffle=True\n    )\n\n    criterion = nn.CrossEntropyLoss().to(device)\n    args.dc_aug_param = get_daparam(dataset, model_name, model_name, None)\n    args.dc_aug_param[\"strategy\"] = \"crop_scale_rotate\"\n\n    model_epoch_params = []\n    \n    for _ in range(num_experts):\n        epoch_model = None\n        net = get_network(model_name, channel, num_classes, im_size, dist=False).to(device)\n        net.train()\n        optim = torch.optim.SGD(\n            net.parameters(),\n            lr=lr_teacher,\n            momentum=momentum,\n            weight_decay=weight_decay\n        )\n        lr_schedule = [train_epochs // 2 + 1]\n\n        for e in tqdm(range(train_epochs)):\n            train_loss, train_acc, epoch_model = epoch(\n                \"train\", trainloader, net, optim, criterion, args, aug=True\n            )\n            test_loss,  test_acc, _  = epoch(\n                \"test\",  testloader, net, None,      criterion, args, aug=False\n            )\n            print(f\"[Epoch {e:3d}]   train_acc={train_acc:.4f}   test_acc={test_acc:.4f}\")\n            model_epoch_params.append([p.detach().cpu() for p in net.parameters()])\n        \n    return model_epoch_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T02:40:23.652956Z","iopub.execute_input":"2025-05-16T02:40:23.653700Z","iopub.status.idle":"2025-05-16T02:40:23.669653Z","shell.execute_reply.started":"2025-05-16T02:40:23.653674Z","shell.execute_reply":"2025-05-16T02:40:23.668901Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"expert_models = expert_train(90)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T02:41:34.128923Z","iopub.execute_input":"2025-05-16T02:41:34.129630Z","iopub.status.idle":"2025-05-16T02:44:36.159433Z","shell.execute_reply.started":"2025-05-16T02:41:34.129605Z","shell.execute_reply":"2025-05-16T02:44:36.158369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(expert_models, \"/kaggle/working/expert_models.pt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}